\section{Overview}

\begin{frame}[standout]
    \Large
    Ask if you have questions \\
    (or want me to explain in more detail)
\end{frame}

\begin{frame}[c]{Plan}
    Individual Parts:
    \begin{itemize}[<+(1)->]
        \item Normal FeedForward MLP
        \item Embedding: Input
        \item Embedding: Location
        \item Basics of Attention (before transformer)
        \item Attention is All You Need \cite{vaswani_attention_2017}
        \item Linear Attention: FastFormer \cite{wu_fastformer_2021} / Flash Attention \cite{hua_transformer_2022}

        \item (fun:) One Model to Learn Them All \cite{kaiser_one_2017}
        \item Distillation / Quantization \cite{polino_model_2018}
    \end{itemize}
\end{frame}


\begin{frame}[c]{Overview}
    \begin{figure}
        \begin{columns}
            \column{0.8\linewidth}
            \includegraphics[height=0.9\textheight]{transformer}
            % \column{0.2\linewidth}
            \column{\dimexpr0.15\linewidth+9em}
            \raisebox{3em}{Image Source: \cite{vaswani_attention_2017}}
        \end{columns}
    \end{figure}
\end{frame}
